{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /4TB/popenov/PiCapcha\n",
    "\n",
    "# !mkdir /4TB/popenov/PiCapcha/dataset\n",
    "# !mkdir /4TB/popenov/PiCapcha/dataset/train\n",
    "# !mkdir /4TB/popenov/PiCapcha/dataset/test\n",
    "\n",
    "# !mkdir /4TB/popenov/PiCapcha/models\n",
    "# !mkdir /4TB/popenov/PiCapcha/results\n",
    "# !mkdir /4TB/popenov/PiCapcha/models/MNv2/\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  8 22:10:57 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 60%   74C    P2   146W / 250W |   6090MiB / 11172MiB |     59%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 45%   68C    P2    59W / 250W |     10MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 34%   62C    P8    20W / 250W |     10MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:42:00.0 Off |                  N/A |\n",
      "|  0%   56C    P8    20W / 250W |     10MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      7017      C   ...slovskiy/anaconda3/envs/py35/bin/python   143MiB |\n",
      "|    0     41421      C   python3                                     5937MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=-1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_IN_CLASS = 5000\n",
    "NUM_CLASSES = 345\n",
    "TEST_PART = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/googlecreativelab/quickdraw-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp quickdraw-dataset/categories.txt /4TB/popenov/PiCapcha/dataset/categories.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from quickdraw import QuickDrawData, QuickDrawDataGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '/4TB/popenov/PiCapcha/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_num = int(SAMPLES_IN_CLASS * TEST_PART)\n",
    "train_samples_num = SAMPLES_IN_CLASS - test_samples_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(DATASET_ROOT, 'categories.txt')) as f:\n",
    "#     for name in f.readlines():\n",
    "#         name = name.strip()\n",
    "#         data = QuickDrawDataGroup(name, max_drawings=SAMPLES_IN_CLASS, recognized=True)\n",
    "        \n",
    "#         i = 0\n",
    "#         for sample in data.drawings:\n",
    "#             if i < train_samples:\n",
    "#                 if not os.path.isdir(os.path.join(DATASET_ROOT, 'train/'+name)):\n",
    "#                     os.mkdir(os.path.join(DATASET_ROOT, 'train/'+name))\n",
    "#                 sample.image.save(DATASET_ROOT+'/train/'+name+'/'+str(sample.key_id)+'.png')\n",
    "#                 i += 1\n",
    "#             else:\n",
    "#                 if not os.path.isdir(os.path.join(DATASET_ROOT, 'test/'+name)):\n",
    "#                         os.mkdir(os.path.join(DATASET_ROOT, 'test/'+name))\n",
    "#                 sample.image.save(DATASET_ROOT+'/test/'+name+'/'+str(sample.key_id)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224,224,3)\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = Input(shape=INPUT_SHAPE)\n",
    "# model = input_tensor\n",
    "# model = Lambda(preprocess_input, name='preprocessing')(model)\n",
    "# model = MobileNet(input_shape=(224,224,3), include_top=False, weights='imagenet')(model)\n",
    "# model = GlobalAveragePooling2D()(model)\n",
    "# model = Dropout(0.5)(model)\n",
    "# model = Dense(NUM_CLASSES, activation='softmax')(model)\n",
    "# model = Model(inputs=input_tensor, outputs=model)\n",
    "# opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE/NUM_EPOCHS)\n",
    "# model.compile(loss=categorical_crossentropy, optimizer=opt, metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# TRAIN_PATH = os.path.join(DATASET_ROOT, 'train')\n",
    "# filepaths = []\n",
    "# y = dict()\n",
    "# number2category = dict()\n",
    "# for dir_number, directory in enumerate(sorted(os.listdir(TRAIN_PATH))):\n",
    "#     number2category[dir_number] = directory\n",
    "#     for filename in os.listdir(os.path.join(TRAIN_PATH, directory)):\n",
    "#         filepath = os.path.join(TRAIN_PATH, directory, filename)\n",
    "#         filepaths.append(filepath)\n",
    "#         y[filepath] = dir_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class InputGenerator(object):\n",
    "#     def __init__(self, filepaths, y, batch_size=8, img_size=224, shuffle=True):\n",
    "#         self.num_classes = NUM_CLASSES\n",
    "#         def generator():\n",
    "#             while True:\n",
    "#                 order = np.arange(len(filepaths))\n",
    "#                 if shuffle:\n",
    "#                     np.random.shuffle(order)\n",
    "\n",
    "#                 n_batches = len(order) // batch_size\n",
    "#                 for i in range(n_batches):\n",
    "#                     batch_order = order[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "#                     batch_filepaths = []\n",
    "#                     for ord in batch_order:\n",
    "#                         batch_filepaths.append(filepaths[ord])\n",
    "\n",
    "#                     batch_x = np.zeros((batch_size, img_size, img_size, 3), dtype=np.uint8)\n",
    "#                     batch_y = np.zeros((batch_size, self.num_classes), dtype=float)\n",
    "#                     for k, filepath in enumerate(batch_filepaths):\n",
    "#                         img = cv2.imread(filepath)\n",
    "#                         img = cv2.resize(img, (img_size, img_size))\n",
    "#                         batch_x[k] = img[:, :, ::-1]\n",
    "#                         batch_y[k][y[filepath]] = 1\n",
    "\n",
    "#                     batch_x = batch_x.astype(\"float\")\n",
    "#                     yield batch_x, batch_y\n",
    "\n",
    "#         self.generator = generator()\n",
    "#         self.steps = len(filepaths) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_SAVE_PATH = '/4TB/popenov/PiCapcha/models/MNv2/'\n",
    "# MODEL_DIR_NAME = 'first_try'\n",
    "\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "#             os.path.join(MODEL_SAVE_PATH, MODEL_DIR_NAME)+\"_{epoch:02d}.hdf5\",\n",
    "#             monitor='val_loss',\n",
    "#             verbose=0,\n",
    "#             save_best_only=False,\n",
    "#             save_weights_only=False,\n",
    "#             mode='auto',\n",
    "#             period=1\n",
    "# )\n",
    "\n",
    "# # print(np.unique(list(y.values())))\n",
    "# # print(filepaths)\n",
    "\n",
    "# model.fit_generator(InputGenerator(filepaths, y, batch_size=BATCH_SIZE).generator,\n",
    "#                     epochs=NUM_EPOCHS,\n",
    "#                     steps_per_epoch=min(1000, len(filepaths) // BATCH_SIZE),\n",
    "#                     callbacks=[checkpoint]\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2 (default, Nov 23 2017, 16:37:01) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _preprocess_symbolic_input\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# print(keras.__version__)\n",
    "\n",
    "MODEL_PATH = '/4TB/popenov/PiCapcha/models/MNv2/first_try_85.hdf5'\n",
    "\n",
    "model = load_model(MODEL_PATH, custom_objects={'tf':tf, 'relu6':tf.nn.relu6, \n",
    "                                              'preprocess_input':preprocess_input,\n",
    "                                              '_preprocess_symbolic_input':_preprocess_symbolic_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_one_image(model, image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "    img = img[:, :, ::-1]\n",
    "    \n",
    "    model_input = np.expand_dims(img, axis=0)\n",
    "    model_output = model.predict(model_input)\n",
    "    \n",
    "    category_number = np.argmax(model_output)\n",
    "    \n",
    "    return category_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/750 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "TEST_PATH = '/4TB/popenov/PiCapcha/dataset/test/'\n",
    "\n",
    "answers = []\n",
    "true_answers = []\n",
    "\n",
    "number2category = dict()\n",
    "for dir_number, directory in enumerate(sorted(os.listdir(TEST_PATH))):\n",
    "    number2category[dir_number] = directory\n",
    "\n",
    "category2num = {k:v for v,k in number2category.items()}\n",
    "\n",
    "for directory in os.listdir(TEST_PATH):\n",
    "    for img_name in tqdm(os.listdir(os.path.join(TEST_PATH, directory))):\n",
    "        answers.append(test_on_one_image(model, os.path.join(TEST_PATH, directory, img_name)))\n",
    "        true_answers.append(category2num[directory])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./category_num_to_name.pickle', 'wb') as f:\n",
    "    pickle.dump(number2category, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902531400966184"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true_answers, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.2 ms ± 578 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "true_answers.append(test_on_one_image(model, os.path.join(TEST_PATH, directory, img_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
